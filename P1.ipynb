{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import numpy as np\n",
    "import cv2\n",
    "import math\n",
    "from moviepy.editor import VideoFileClip\n",
    "from IPython.display import HTML\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "def region_of_interest(img, vertices):\n",
    "    #defining a blank mask to start with\n",
    "    mask = np.zeros_like(img)   \n",
    "    \n",
    "    #defining a 3 channel or 1 channel color to fill the mask with depending on the input image\n",
    "    if len(img.shape) > 2:\n",
    "        channel_count = img.shape[2]  # i.e. 3 or 4 depending on your image\n",
    "        ignore_mask_color = (255,) * channel_count\n",
    "    else:\n",
    "        ignore_mask_color = 255\n",
    "        \n",
    "    #filling pixels inside the polygon defined by \"vertices\" with the fill color    \n",
    "    cv2.fillPoly(mask, vertices, ignore_mask_color)\n",
    "    \n",
    "    #returning the image only where mask pixels are nonzero\n",
    "    masked_image = cv2.bitwise_and(img, mask)\n",
    "    return masked_image\n",
    "\n",
    "\n",
    "# highlight edges using canny\n",
    "def highlight_edges(image):\n",
    "    # mask white and yellow color\n",
    "    filtered = filter_white_yellow(image)\n",
    "    \n",
    "    # blur input\n",
    "    blurred = cv2.GaussianBlur(filtered, (5, 5), 0)\n",
    "\n",
    "    # convert to grayscale\n",
    "    gray = cv2.cvtColor(blurred, cv2.COLOR_RGB2GRAY)   \n",
    "\n",
    "    # highlight edges\n",
    "    return cv2.Canny(gray, 100, 200)\n",
    "\n",
    "\n",
    "# calculate a viewport\n",
    "def calculate_viewport(width, height, side):\n",
    "    # camera-specific parameters!\n",
    "    field_depth = int(height * 0.4)\n",
    "    field_width_near = int(width * 0.85)\n",
    "    field_width_far = int(width * 0.08)\n",
    "\n",
    "    if (side == \"left\"):\n",
    "        region = np.array([[[(width - field_width_near) / 2, height - 1],\n",
    "                            [(width - field_width_far) / 2, height - field_depth],\n",
    "                            [width / 2, height - field_depth],\n",
    "                            [width / 2, height - 1]]], dtype=np.int32)\n",
    "    elif (side == \"right\"):\n",
    "        region = np.array([[[width / 2, height - 1],\n",
    "                            [width / 2, height - field_depth],\n",
    "                            [width - (width - field_width_far) / 2, height - field_depth],\n",
    "                            [width - (width - field_width_near) / 2, height - 1]]],\n",
    "                          dtype=np.int32)\n",
    "    else:\n",
    "        region = np.array([[[(width - field_width_near) / 2, height - 1],\n",
    "                            [(width - field_width_far) / 2, height - field_depth],\n",
    "                            [width / 2, height - field_depth],\n",
    "                            [width - (width - field_width_far) / 2, height - field_depth],\n",
    "                            [width - (width - field_width_near) / 2, height - 1]]],\n",
    "                          dtype=np.int32)\n",
    "\n",
    "    return region\n",
    "\n",
    "\n",
    "# extract lines from an canny-edge-image using hough + mask\n",
    "def extract_lines(image, side):\n",
    "    height = image.shape[0]\n",
    "    width = image.shape[1]\n",
    "\n",
    "    viewport = calculate_viewport(width, height, side)\n",
    "    masked_edges = region_of_interest(image, viewport)\n",
    "\n",
    "    threshold = 9     # minimum number of votes (intersections in Hough grid cell)\n",
    "    min_line_length = 12 #minimum number of pixels making up a line\n",
    "    max_line_gap = 5    # maximum gap in pixels between connectable line segments\n",
    "    return cv2.HoughLinesP(masked_edges, 1, np.pi/180, threshold, np.array([]), min_line_length, max_line_gap)\n",
    "\n",
    "\n",
    "# render all lines into the image\n",
    "def draw_lines(img, lines, color=[255, 0, 0], thickness = 10):\n",
    "    if lines is None:\n",
    "        return\n",
    "\n",
    "    for line in lines:\n",
    "        for x1, y1, x2, y2 in line:\n",
    "            cv2.line(img, (x1, y1), (x2, y2), color, thickness)\n",
    "\n",
    "\n",
    "def draw_viewport(img, color=[0, 0, 255], thickness = 2):\n",
    "    viewport = calculate_viewport(img.shape[1], img.shape[0], \"complete\")\n",
    "    for i in range(0, 4):\n",
    "        cv2.line(img,\n",
    "                 (viewport[0, i, 0], viewport[0, i, 1]),\n",
    "                 (viewport[0, i+1, 0], viewport[0, i+1, 1]), color, thickness)\n",
    "\n",
    "\n",
    "# drop lines that have a low slope (parallel to camera)\n",
    "def slope_filter(lines):\n",
    "    result = []\n",
    "    if lines is not None:\n",
    "        for line in lines:\n",
    "            for x1,y1,x2,y2 in line:\n",
    "                if (abs(y2 - y1) == 0):\n",
    "                    slope = 0\n",
    "                else:\n",
    "                    slope = abs(x2 - x1) / abs(y2 - y1)\n",
    "                # only keep lines that are more in the direction south/north\n",
    "                # than east/west (slope >45 degrees)\n",
    "                if (slope > 1.0):\n",
    "                    result.append(line)\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "# find best matching 1d-poly and draw on full width\n",
    "def approximate_line(lines, image_width, enable_slope_filter=True):\n",
    "    if lines is None:\n",
    "        return [];\n",
    "    \n",
    "    if enable_slope_filter:\n",
    "        lines = slope_filter(lines)\n",
    "\n",
    "    x = []\n",
    "    y = []\n",
    "    for line in lines:\n",
    "        for x1, y1, x2, y2 in line:\n",
    "            x.append(x1)\n",
    "            y.append(y1)\n",
    "            x.append(x2)\n",
    "            y.append(y2)\n",
    "\n",
    "    if (not x or not y):\n",
    "        return []\n",
    "\n",
    "    fit = np.poly1d(np.polyfit(x, y, 1))\n",
    "    return [[[0, int(fit(0)), image_width, int(fit(image_width))]]]\n",
    "\n",
    "\n",
    "def filter_white_yellow(image):\n",
    "    hue = cv2.cvtColor(image, cv2.COLOR_RGB2HSV)   \n",
    "\n",
    "    lower_yellow = np.array([20, 50, 50])\n",
    "    upper_yellow = np.array([40, 255, 255])\n",
    "    mask_yellow = cv2.inRange(hue, lower_yellow, upper_yellow)\n",
    "\n",
    "    lower_white = np.array([200, 200, 200])\n",
    "    upper_white = np.array([255, 255, 255])\n",
    "    mask_white = cv2.inRange(image, lower_white, upper_white)\n",
    "\n",
    "    # mask white and yellow-ish areas in original image\n",
    "    mask = mask_yellow + mask_white\n",
    "    res = cv2.bitwise_and(image, image, mask=mask)\n",
    "    return res\n",
    "\n",
    "\n",
    "def process_image(image):\n",
    "    edges = highlight_edges(image)\n",
    "    lines_left = extract_lines(edges, \"left\")\n",
    "    lines_right = extract_lines(edges, \"right\")\n",
    "    \n",
    "    # find optimal lines (one per side)\n",
    "    left = approximate_line(lines_left, image.shape[1])\n",
    "    right = approximate_line(lines_right, image.shape[1])\n",
    "\n",
    "    # render optimized lines\n",
    "    line_image = np.copy(image)*0\n",
    "    draw_lines(line_image, left)\n",
    "    draw_lines(line_image, right)\n",
    "    # cut lines on below horizon\n",
    "    line_image = region_of_interest(line_image,\n",
    "                                    calculate_viewport(image.shape[1], image.shape[0], \"complete\"))\n",
    "                                    \n",
    "    # enable to add raw detected lines + viewport to output\n",
    "    if False:\n",
    "        raw_line_image = np.copy(line_image)*0\n",
    "        draw_lines(raw_line_image, lines_left, [0,255,0], 3)\n",
    "        draw_lines(raw_line_image, lines_right, [0,255,0], 3)\n",
    "        draw_viewport(raw_line_image)\n",
    "        # blend into rendering of optimized lines\n",
    "        line_image = cv2.addWeighted(raw_line_image, 0.8, line_image, 1, 0)\n",
    "\n",
    "    return cv2.addWeighted(image, 1, line_image, 0.5, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] >>>> Building video white.mp4\n",
      "[MoviePy] Writing video white.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 221/222 [00:06<00:00, 33.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] Done.\n",
      "[MoviePy] >>>> Video ready: white.mp4 \n",
      "\n",
      "CPU times: user 5.75 s, sys: 513 ms, total: 6.27 s\n",
      "Wall time: 6.78 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<video width=\"960\" height=\"540\" controls>\n",
       "  <source src=\"        white.mp4\">\n",
       "</video>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "white_output = 'white.mp4'\n",
    "clip1 = VideoFileClip(\"solidWhiteRight.mp4\")\n",
    "white_clip = clip1.fl_image(process_image)\n",
    "%time white_clip.write_videofile(white_output, audio=False)\n",
    "\n",
    "HTML(\"\"\"\n",
    "<video width=\"960\" height=\"540\" controls>\n",
    "  <source src=\"        {0}\">\n",
    "</video>\n",
    "\"\"\".format(white_output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] >>>> Building video yellow.mp4\n",
      "[MoviePy] Writing video yellow.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 681/682 [00:20<00:00, 33.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] Done.\n",
      "[MoviePy] >>>> Video ready: yellow.mp4 \n",
      "\n",
      "CPU times: user 19 s, sys: 783 ms, total: 19.8 s\n",
      "Wall time: 21.1 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<video width=\"960\" height=\"540\" controls>\n",
       "  <source src=\"yellow.mp4\">\n",
       "</video>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yellow_output = 'yellow.mp4'\n",
    "clip2 = VideoFileClip('solidYellowLeft.mp4')\n",
    "yellow_clip = clip2.fl_image(process_image)\n",
    "%time yellow_clip.write_videofile(yellow_output, audio=False)\n",
    "\n",
    "HTML(\"\"\"\n",
    "<video width=\"960\" height=\"540\" controls>\n",
    "  <source src=\"{0}\">\n",
    "</video>\n",
    "\"\"\".format(yellow_output))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Writeup and Submission\n",
    "\n",
    "If you're satisfied with your video outputs, it's time to make the report writeup in a pdf or markdown file. Once you have this Ipython notebook ready along with the writeup, it's time to submit for review! Here is a [link](https://github.com/udacity/CarND-LaneLines-P1/blob/master/writeup_template.md) to the writeup template file.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Optional Challenge\n",
    "\n",
    "Try your lane finding pipeline on the video below.  Does it still work?  Can you figure out a way to make it more robust?  If you're up for the challenge, modify your pipeline so it works with this video and submit it along with the rest of your project!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] >>>> Building video extra.mp4\n",
      "[MoviePy] Writing video extra.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 251/251 [00:17<00:00, 14.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] Done.\n",
      "[MoviePy] >>>> Video ready: extra.mp4 \n",
      "\n",
      "CPU times: user 13.3 s, sys: 903 ms, total: 14.2 s\n",
      "Wall time: 19.4 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<video width=\"960\" height=\"540\" controls>\n",
       "  <source src=\"extra.mp4\">\n",
       "</video>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "challenge_output = 'extra.mp4'\n",
    "clip2 = VideoFileClip('challenge.mp4')\n",
    "challenge_clip = clip2.fl_image(process_image)\n",
    "%time challenge_clip.write_videofile(challenge_output, audio=False)\n",
    "HTML(\"\"\"\n",
    "<video width=\"960\" height=\"540\" controls>\n",
    "  <source src=\"{0}\">\n",
    "</video>\n",
    "\"\"\".format(challenge_output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
